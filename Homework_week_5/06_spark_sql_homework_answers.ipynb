{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3bb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db6033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H5Q1\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf19bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhvhv = spark.read.parquet('fhvhv/2021/06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0a5c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02765|2021-06-01 08:08:00|2021-06-01 08:23:45|         236|         100|      N|                B02765|\n",
      "|              B02835|2021-06-03 16:42:36|2021-06-03 16:57:33|         119|          78|      N|                B02835|\n",
      "|              B02765|2021-06-03 06:28:12|2021-06-03 06:51:04|         231|          42|      N|                B02765|\n",
      "|              B02887|2021-06-02 17:48:58|2021-06-02 18:05:18|          33|         144|      N|                B02887|\n",
      "|              B02510|2021-06-04 12:38:39|2021-06-04 13:22:22|         219|          85|      N|                  null|\n",
      "|              B02866|2021-06-04 01:42:58|2021-06-04 01:58:41|         148|         145|      N|                B02866|\n",
      "|              B02510|2021-06-03 21:07:19|2021-06-03 21:22:50|          39|          91|      N|                  null|\n",
      "|              B02871|2021-06-01 16:47:07|2021-06-01 16:50:58|         181|         181|      N|                B02871|\n",
      "|              B02864|2021-06-02 08:01:43|2021-06-02 08:06:26|          51|          81|      N|                B02864|\n",
      "|              B02835|2021-06-03 17:52:41|2021-06-03 18:01:57|         233|         237|      N|                B02835|\n",
      "|              B02866|2021-06-02 07:08:33|2021-06-02 07:18:42|          81|         250|      N|                B02866|\n",
      "|              B02800|2021-06-03 08:29:02|2021-06-03 08:41:33|         140|         162|      N|                  null|\n",
      "|              B02883|2021-06-01 18:36:55|2021-06-01 18:57:52|          80|          66|      N|                B02883|\n",
      "|              B02835|2021-06-04 15:34:56|2021-06-04 15:51:15|         191|         205|      N|                B02835|\n",
      "|              B02872|2021-06-02 21:06:24|2021-06-02 21:20:03|          61|          17|      N|                B02872|\n",
      "|              B02884|2021-06-03 07:27:45|2021-06-03 07:32:05|         237|         237|      N|                B02884|\n",
      "|              B02872|2021-06-03 09:38:37|2021-06-03 09:48:01|          90|          48|      N|                B02872|\n",
      "|              B02510|2021-06-02 18:39:30|2021-06-02 19:10:45|         138|         148|      N|                  null|\n",
      "|              B02510|2021-06-02 17:49:32|2021-06-02 18:32:30|          91|          71|      N|                  null|\n",
      "|              B02510|2021-06-04 12:01:10|2021-06-04 12:18:58|          92|          73|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhvhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8c950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhvhv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485ddc9",
   "metadata": {},
   "source": [
    "Useful function if you have two df of similar data (like green and yellow taxi trips) and would like to union them on the common list of columns you can use:\n",
    "- to see list of columns of each df: df_green.columns\n",
    "- to compare two df columns: set(df_green.columns) & set(df_yellow.columns)\n",
    "\n",
    "Below is function to create a common column list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_columns = []\n",
    "\n",
    "# yellow_columns = set(df.yellow.columns)\n",
    "\n",
    "# for col in df_green.columns:\n",
    "#     if col in yellow_columns:\n",
    "#         common_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55878465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4d3542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------+\n",
      "|to_date(pickup_datetime)| count|\n",
      "+------------------------+------+\n",
      "|              2021-06-22|469568|\n",
      "|              2021-06-04|538917|\n",
      "|              2021-06-20|491630|\n",
      "|              2021-06-27|509437|\n",
      "|              2021-06-28|425909|\n",
      "|              2021-06-01|417375|\n",
      "|              2021-06-17|497133|\n",
      "|              2021-06-13|509039|\n",
      "|              2021-06-19|601189|\n",
      "|              2021-06-02|457339|\n",
      "|              2021-06-08|462554|\n",
      "|              2021-06-26|592505|\n",
      "|              2021-06-09|483353|\n",
      "|              2021-06-14|426672|\n",
      "|              2021-06-29|456586|\n",
      "|              2021-06-07|425771|\n",
      "|              2021-06-06|522753|\n",
      "|              2021-06-11|549286|\n",
      "|              2021-06-18|540056|\n",
      "|              2021-06-21|419024|\n",
      "+------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to see distribution by date\n",
    "df_fhvhv.groupBy(F.to_date('pickup_datetime')).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193ab419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\spark-3.3.2-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# To use actual SQL with Spark, we need to first define the table:\n",
    "df_fhvhv.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I would like to create new columns for the date made out of the timestamp, I can use the code below:\n",
    "\n",
    "# df_fhvhv \\\n",
    "#     .withColumn('pickup_date', F.to_date(df_fhvhv.pickup_datetime)) \\\n",
    "#     .withColumn('dropoff_date', F.to_date(df_fhvhv.dropoff_datetime)) \\\n",
    "#     .select('dispatching_base_num','pickup_datetime', 'pickup_date', 'dropoff_datetime', 'dropoff_date', 'PULocationID', 'DOLocationID''SR_Flag', 'Affiliated_base_number') \\\n",
    "#     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46fffc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|           trip_day|num_rides|\n",
      "+-------------------+---------+\n",
      "|2021-06-03 00:00:00|   521408|\n",
      "|2021-06-06 00:00:00|   522753|\n",
      "|2021-06-07 00:00:00|   425771|\n",
      "|2021-06-27 00:00:00|   509437|\n",
      "|2021-06-01 00:00:00|   417375|\n",
      "|2021-06-10 00:00:00|   504108|\n",
      "|2021-06-21 00:00:00|   419024|\n",
      "|2021-06-15 00:00:00|   452470|\n",
      "|2021-06-24 00:00:00|   500596|\n",
      "|2021-06-23 00:00:00|   474599|\n",
      "|2021-06-17 00:00:00|   497133|\n",
      "|2021-06-19 00:00:00|   601189|\n",
      "|2021-06-05 00:00:00|   604903|\n",
      "|2021-06-12 00:00:00|   591339|\n",
      "|2021-06-20 00:00:00|   491630|\n",
      "|2021-06-28 00:00:00|   425909|\n",
      "|2021-06-16 00:00:00|   479776|\n",
      "|2021-06-11 00:00:00|   549286|\n",
      "|2021-06-13 00:00:00|   509039|\n",
      "|2021-06-18 00:00:00|   540056|\n",
      "+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# H5Q3:\n",
    "\n",
    "df_h5q3 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('day', pickup_datetime) AS trip_day, \n",
    "    count(*) AS num_rides\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3d1a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column representing duration of the ride in seconds\n",
    "\n",
    "new_df = df_fhvhv \\\n",
    "    .withColumn('hours_between', (df_fhvhv.dropoff_datetime - df_fhvhv.pickup_datetime)/360) \\\n",
    "    .select('dispatching_base_num','pickup_datetime', 'dropoff_datetime', 'hours_between', 'PULocationID', 'DOLocationID', 'SR_Flag', 'Affiliated_base_number') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e89702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+--------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|       hours_between|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+--------------------+------------+------------+-------+----------------------+\n",
      "|              B02765|2021-06-01 08:08:00|2021-06-01 08:23:45|INTERVAL '0 00:00...|         236|         100|      N|                B02765|\n",
      "|              B02835|2021-06-03 16:42:36|2021-06-03 16:57:33|INTERVAL '0 00:00...|         119|          78|      N|                B02835|\n",
      "|              B02765|2021-06-03 06:28:12|2021-06-03 06:51:04|INTERVAL '0 00:00...|         231|          42|      N|                B02765|\n",
      "|              B02887|2021-06-02 17:48:58|2021-06-02 18:05:18|INTERVAL '0 00:00...|          33|         144|      N|                B02887|\n",
      "|              B02510|2021-06-04 12:38:39|2021-06-04 13:22:22|INTERVAL '0 00:00...|         219|          85|      N|                  null|\n",
      "|              B02866|2021-06-04 01:42:58|2021-06-04 01:58:41|INTERVAL '0 00:00...|         148|         145|      N|                B02866|\n",
      "|              B02510|2021-06-03 21:07:19|2021-06-03 21:22:50|INTERVAL '0 00:00...|          39|          91|      N|                  null|\n",
      "|              B02871|2021-06-01 16:47:07|2021-06-01 16:50:58|INTERVAL '0 00:00...|         181|         181|      N|                B02871|\n",
      "|              B02864|2021-06-02 08:01:43|2021-06-02 08:06:26|INTERVAL '0 00:00...|          51|          81|      N|                B02864|\n",
      "|              B02835|2021-06-03 17:52:41|2021-06-03 18:01:57|INTERVAL '0 00:00...|         233|         237|      N|                B02835|\n",
      "|              B02866|2021-06-02 07:08:33|2021-06-02 07:18:42|INTERVAL '0 00:00...|          81|         250|      N|                B02866|\n",
      "|              B02800|2021-06-03 08:29:02|2021-06-03 08:41:33|INTERVAL '0 00:00...|         140|         162|      N|                  null|\n",
      "|              B02883|2021-06-01 18:36:55|2021-06-01 18:57:52|INTERVAL '0 00:00...|          80|          66|      N|                B02883|\n",
      "|              B02835|2021-06-04 15:34:56|2021-06-04 15:51:15|INTERVAL '0 00:00...|         191|         205|      N|                B02835|\n",
      "|              B02872|2021-06-02 21:06:24|2021-06-02 21:20:03|INTERVAL '0 00:00...|          61|          17|      N|                B02872|\n",
      "|              B02884|2021-06-03 07:27:45|2021-06-03 07:32:05|INTERVAL '0 00:00...|         237|         237|      N|                B02884|\n",
      "|              B02872|2021-06-03 09:38:37|2021-06-03 09:48:01|INTERVAL '0 00:00...|          90|          48|      N|                B02872|\n",
      "|              B02510|2021-06-02 18:39:30|2021-06-02 19:10:45|INTERVAL '0 00:00...|         138|         148|      N|                  null|\n",
      "|              B02510|2021-06-02 17:49:32|2021-06-02 18:32:30|INTERVAL '0 00:00...|          91|          71|      N|                  null|\n",
      "|              B02510|2021-06-04 12:01:10|2021-06-04 12:18:58|INTERVAL '0 00:00...|          92|          73|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+--------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c83ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.registerTempTable('trips_data_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19fdb618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|           trip_day|       hours_between|\n",
      "+-------------------+--------------------+\n",
      "|2021-06-25 00:00:00|INTERVAL '0 00:11...|\n",
      "|2021-06-22 00:00:00|INTERVAL '0 00:04...|\n",
      "|2021-06-27 00:00:00|INTERVAL '0 00:03...|\n",
      "|2021-06-26 00:00:00|INTERVAL '0 00:03...|\n",
      "|2021-06-23 00:00:00|INTERVAL '0 00:02...|\n",
      "+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# H5Q4:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('day', pickup_datetime) AS trip_day, \n",
    "    hours_between\n",
    "FROM\n",
    "    trips_data_new\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "104be736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+\n",
      "|           trip_day|hours_between|\n",
      "+-------------------+-------------+\n",
      "|2021-06-25 00:00:00|           66|\n",
      "|2021-06-22 00:00:00|           25|\n",
      "|2021-06-27 00:00:00|           19|\n",
      "|2021-06-26 00:00:00|           18|\n",
      "|2021-06-23 00:00:00|           16|\n",
      "+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# H5Q4:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('day', pickup_datetime) AS trip_day, \n",
    "    timestampdiff(hour, pickup_datetime, dropoff_datetime) AS hours_between\n",
    "FROM\n",
    "    trips_data\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ad8e5",
   "metadata": {},
   "source": [
    " Loading the Zone Lookup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2183ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d0bd5a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID        Borough                     Zone service_zone\n",
       "0             1            EWR           Newark Airport          EWR\n",
       "1             2         Queens              Jamaica Bay    Boro Zone\n",
       "2             3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3             4      Manhattan            Alphabet City  Yellow Zone\n",
       "4             5  Staten Island            Arden Heights    Boro Zone\n",
       "..          ...            ...                      ...          ...\n",
       "260         261      Manhattan       World Trade Center  Yellow Zone\n",
       "261         262      Manhattan           Yorkville East  Yellow Zone\n",
       "262         263      Manhattan           Yorkville West  Yellow Zone\n",
       "263         264        Unknown                       NV          NaN\n",
       "264         265        Unknown                      NaN          NaN\n",
       "\n",
       "[265 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what this file is composed of to create correct schema\n",
    "df_zone=pd.read_csv(\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\")\n",
    "df_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ecc2980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocationID       int64\n",
       "Borough         object\n",
       "Zone            object\n",
       "service_zone    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zone.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "891d5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "463c5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_schema = types.StructType([\n",
    "    types.StructField('LocationID', types.IntegerType(), True),\n",
    "    types.StructField('Borough', types.StringType(), True),\n",
    "    types.StructField('Zone', types.StringType(), True),\n",
    "    types.StructField('service_zone', types.StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b336cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-03-05 14:32:53--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230305T133300Z&X-Amz-Expires=300&X-Amz-Signature=cab7ac936489459e7ffa8f7e41bf6cf8080616a78ee296a32af599e37280ca6e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-05 14:32:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230305T133300Z&X-Amz-Expires=300&X-Amz-Signature=cab7ac936489459e7ffa8f7e41bf6cf8080616a78ee296a32af599e37280ca6e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: 'taxi_zone_lookup.csv'\n",
      "\n",
      "     0K .......... ..                                         100% 1.05M=0.01s\n",
      "\n",
      "2023-03-05 14:32:53 (1.05 MB/s) - 'taxi_zone_lookup.csv' saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06967978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(zones_schema) \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98386d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone.registerTempTable('zone_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c94b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhvhv.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae33075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|               Zone|pickup_freq|\n",
      "+-------------------+-----------+\n",
      "|Crown Heights North|     231279|\n",
      "|       East Village|     221244|\n",
      "|        JFK Airport|     188867|\n",
      "|     Bushwick South|     187929|\n",
      "|      East New York|     186780|\n",
      "+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# H5Q6:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    zd.Zone, \n",
    "    count(*) AS pickup_freq\n",
    "FROM\n",
    "    trips_data td\n",
    "    left join zone_data zd on td.PULocationID = zd.LocationID\n",
    "GROUP BY 1 \n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
